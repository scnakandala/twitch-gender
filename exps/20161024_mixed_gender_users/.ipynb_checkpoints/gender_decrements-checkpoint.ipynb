{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "WARNING: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from sklearn import decomposition\n",
    "import numpy as np  \n",
    "import sys\n",
    "import operator\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from adjustText import adjust_text\n",
    "from gensim.models.doc2vec import LabeledSentence, Doc2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import re\n",
    "import os\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from random import shuffle\n",
    "import collections\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from heapq import nlargest\n",
    "\n",
    "from twitch import commons\n",
    "\n",
    "%pylab inline\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pylab as pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all users: 1684452\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./user_chat_counts.csv.dat', header=None, names=['users', 'total', 'male', 'female'])\n",
    "df['female_chat_percentage'] = (df.female*100)/df.total\n",
    "\n",
    "print('all users: ' + str(len(df.index)))\n",
    "\n",
    "female_only = df[(df.total >= 100) & (df.female_chat_percentage == 100)].users.values.tolist()\n",
    "\n",
    "female_90 = df[(df.total >= 100) & ((df.female_chat_percentage >= 85) \n",
    "                                    & (df.female_chat_percentage < 95))].users.values.tolist()\n",
    "\n",
    "female_80 = df[(df.total >= 100) & ((df.female_chat_percentage >= 75) \n",
    "                                    & (df.female_chat_percentage < 85))].users.values.tolist()\n",
    "\n",
    "female_70 = df[(df.total >= 100) & ((df.female_chat_percentage >= 65) \n",
    "                                    & (df.female_chat_percentage < 75))].users.values.tolist()\n",
    "\n",
    "female_60 = df[(df.total >= 100) & ((df.female_chat_percentage >= 55) \n",
    "                                    & (df.female_chat_percentage < 65))].users.values.tolist()\n",
    "\n",
    "female_50 = df[(df.total >= 100) & ((df.female_chat_percentage >= 45) \n",
    "                                    & (df.female_chat_percentage < 55))].users.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16985\n",
      "4206\n",
      "2201\n",
      "1566\n",
      "1468\n",
      "1322\n"
     ]
    }
   ],
   "source": [
    "print(len(female_only))\n",
    "print(len(female_90))\n",
    "print(len(female_80))\n",
    "print(len(female_70))\n",
    "print(len(female_60))\n",
    "print(len(female_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_female = female_only + female_90 + female_80 + female_70 + female_60 + female_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = [line.strip().split(',')[0] for line in open('../female_channels.csv', 'r')]\n",
    "female_channels = {}\n",
    "for t in temp:\n",
    "    female_channels[t] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "gendered_terms = [r'\\bhe\\b', r'\\bhes', r'\\bshe\\b', r'\\bshes\\b', r'\\bhis\\b', r'\\bher\\b', r'\\bbro\\b',\n",
    "                  r'\\bman\\b', r'\\bsir\\b', r'\\bdude\\b', r'\\bgirl\\b', r'\\bgirls\\b', r'\\blady\\b',\n",
    "                  r'\\bgurl\\b', r'\\bhers\\b', r'\\bhisself\\b', r'\\bherself\\b', r'\\bman\\b', r'\\bwoman\\b']\n",
    "\n",
    "select_users = {}\n",
    "for t in all_female:\n",
    "    select_users[t] = 1\n",
    "\n",
    "user_chats = {}\n",
    "\n",
    "for file_name in os.listdir(\"../../data/channel_chat_logs/cleaned\"):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = \"../../data/channel_chat_logs/cleaned/\" + file_name\n",
    "        with open(file_path, 'r') as fp:\n",
    "            #print('reading : ' + file_path)\n",
    "            for line in fp:\n",
    "                splits = line.split(\",\")\n",
    "                channel = splits[1].replace('#', '')\n",
    "                user = splits[2]\n",
    "                message = splits[3]\n",
    "\n",
    "                # avoiding users with less number of messages\n",
    "                if user not in select_users:\n",
    "                    continue\n",
    "                \n",
    "                if channel not in female_channels:\n",
    "                    continue\n",
    "\n",
    "                for temp in gendered_terms:\n",
    "                    message = re.sub(temp, '', message)\n",
    "\n",
    "                if len(message.strip()) == 0:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    user_chats[user].append(message.strip())\n",
    "                except KeyError:\n",
    "                    user_chats[user] = [message.strip()]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, messages_dic):\n",
    "        self.documents = []\n",
    "        self.messages_dic = messages_dic\n",
    "\n",
    "    def __iter__(self):\n",
    "        for user in self.messages_dic:\n",
    "            messages_list = self.messages_dic[user]\n",
    "            yield LabeledSentence((' '.join(messages_list)).split(), [user])\n",
    "\n",
    "    def to_array(self):\n",
    "        for user in self.messages_dic:\n",
    "            messages_list = self.messages_dic[user]\n",
    "            message_in_one_line = ' '.join(messages_list)\n",
    "            self.documents.append(LabeledSentence(message_in_one_line.split(), [user]))\n",
    "        return self.documents\n",
    "\n",
    "    def sentences_perm(self):\n",
    "        shuffle(self.documents)\n",
    "        return self.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = LabeledLineSentence(user_chats)\n",
    "model = Doc2Vec(min_count=20, window=5, size=100, sample=1e-5, negative=5, workers=8, dm=0, dbow_words=1)\n",
    "model.build_vocab(sentences.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec epoch : 0\n",
      "doc2vec epoch : 1\n",
      "doc2vec epoch : 2\n",
      "doc2vec epoch : 3\n",
      "doc2vec epoch : 4\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('doc2vec epoch : ' + str(epoch))\n",
    "    model.train(sentences.sentences_perm())\n",
    "    model.save('user_all_chats.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector = model['boobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosine_sim_female_only = []\n",
    "cosine_sim_female_90 = []\n",
    "cosine_sim_female_80 = []\n",
    "cosine_sim_female_70 = []\n",
    "cosine_sim_female_60 = []\n",
    "cosine_sim_female_50 = []\n",
    "\n",
    "for u in female_only[0:1000]:\n",
    "    cosine_sim_female_only.append(commons.cosine_similarity(vector, model.docvecs[u]))\n",
    "    \n",
    "for u in female_90[0:1000]:\n",
    "    cosine_sim_female_90.append(commons.cosine_similarity(vector, model.docvecs[u]))\n",
    "    \n",
    "for u in female_80[0:1000]:\n",
    "    cosine_sim_female_80.append(commons.cosine_similarity(vector, model.docvecs[u]))\n",
    "    \n",
    "for u in female_70[0:1000]:\n",
    "    cosine_sim_female_70.append(commons.cosine_similarity(vector, model.docvecs[u]))\n",
    "\n",
    "for u in female_60[0:1000]:\n",
    "    cosine_sim_female_60.append(commons.cosine_similarity(vector, model.docvecs[u]))\n",
    "    \n",
    "for u in female_50[0:1000]:\n",
    "    cosine_sim_female_50.append(commons.cosine_similarity(vector, model.docvecs[u]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0999140497713, 0.0954616419418\n",
      "0.110063096976, 0.0961369410399\n",
      "0.112539763559, 0.107127679625\n",
      "0.117410402488, 0.106512165912\n",
      "0.121650490346, 0.101820436576\n",
      "0.120997122973, 0.106500586478\n"
     ]
    }
   ],
   "source": [
    "print(str(np.mean(cosine_sim_female_only)) + \", \" + str(np.std(cosine_sim_female_only)) )\n",
    "print(str(np.mean(cosine_sim_female_90)) + \", \" + str(np.std(cosine_sim_female_90)) )\n",
    "print(str(np.mean(cosine_sim_female_80)) + \", \" + str(np.std(cosine_sim_female_80)) )\n",
    "print(str(np.mean(cosine_sim_female_70)) + \", \" + str(np.std(cosine_sim_female_70)) )\n",
    "print(str(np.mean(cosine_sim_female_60)) + \", \" + str(np.std(cosine_sim_female_60)) )\n",
    "print(str(np.mean(cosine_sim_female_50)) + \", \" + str(np.std(cosine_sim_female_50)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
