{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "//anaconda/lib/python3.5/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np  \n",
    "import sys\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from random import shuffle\n",
    "\n",
    "sys.path.append('../')\n",
    "from twitch import twitch_commons\n",
    "\n",
    "%pylab inline\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57638\n"
     ]
    }
   ],
   "source": [
    "docvec_ids = [line.split(',')[0] for line in open('./channel_random_message_samples.csv.dat', 'r')]\n",
    "print(len(docvec_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57638\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "female_channels = [line.strip() for line in open('../female_channels.csv', 'r')]\n",
    "male_channels = [line.strip() for line in open('../male_channels.csv', 'r')]\n",
    "for docvec_id in docvec_ids:\n",
    "    splits = docvec_id.split('_')\n",
    "    if len(splits) == 2:\n",
    "        channel = splits[0]\n",
    "    elif len(splits) == 3:\n",
    "        channel = splits[0] + \"_\" + splits[1]\n",
    "    if channel in female_channels:\n",
    "        channel_type = 1\n",
    "        channel_rank = female_channels.index(channel)\n",
    "        quartile = (channel_rank//50) + 1\n",
    "    else :\n",
    "        channel_type = 0\n",
    "        channel_rank = male_channels.index(channel)\n",
    "        quartile = (channel_rank//50) + 1\n",
    "        \n",
    "    df_list.append((docvec_id, channel, channel_type, channel_rank, quartile)) \n",
    "\n",
    "print(len(df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(df_list)\n",
    "channel_df = pd.DataFrame(df_list, columns=['docvec_index', 'channel', 'gender', 'channel_rank', 'quartile'])\n",
    "\n",
    "gender_list = channel_df.gender.values.tolist()\n",
    "quartile_list = channel_df.quartile.values.tolist()\n",
    "rank_list = channel_df.channel_rank.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('./channel_chats.d2v')\n",
    "\n",
    "feature_vectors = [model.docvecs[x] for x in channel_df.docvec_index.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57638\n"
     ]
    }
   ],
   "source": [
    "no_of_channels = len(feature_vectors)\n",
    "print(no_of_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_classification_model(train_arrays, train_labels, test_arrays, test_lebels):\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(train_arrays, train_labels)\n",
    "    print('model accuracy : ' + str(classifier.score(test_arrays, test_labels)))\n",
    "    predict_score = classifier.predict_proba(test_arrays)[:,1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, predict_score)\n",
    "    twitch_commons.plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainig_data_size = no_of_channels//2\n",
    "train_arrays = numpy.zeros((trainig_data_size, 100))\n",
    "train_labels = numpy.zeros(trainig_data_size)\n",
    "test_arrays = numpy.zeros((no_of_channels-trainig_data_size, 100))\n",
    "test_labels = numpy.zeros(no_of_channels-trainig_data_size)\n",
    "\n",
    "for i in range(trainig_data_size):\n",
    "    train_arrays[i] = feature_vectors[i]\n",
    "    train_labels[i] = gender_list[i]\n",
    "\n",
    "for i in range(no_of_channels - trainig_data_size):\n",
    "    test_arrays[i] = feature_vectors[trainig_data_size + i]\n",
    "    test_labels[i] = gender_list[trainig_data_size+i]\n",
    "    \n",
    "build_classification_model(train_arrays, train_labels, test_arrays, test_labels)\n",
    "\n",
    "trainig_data_size = no_of_channels//2\n",
    "train_arrays = numpy.zeros((trainig_data_size, 101))\n",
    "train_labels = numpy.zeros(trainig_data_size)\n",
    "test_arrays = numpy.zeros((no_of_channels-trainig_data_size, 101))\n",
    "test_labels = numpy.zeros(no_of_channels-trainig_data_size)\n",
    "\n",
    "for i in range(trainig_data_size):\n",
    "    train_arrays[i] = np.append(feature_vectors[i],quartile_list[i])\n",
    "    train_labels[i] = gender_list[i]\n",
    "\n",
    "for i in range(no_of_channels - trainig_data_size):\n",
    "    test_arrays[i] = np.append(feature_vectors[trainig_data_size + i],quartile_list[trainig_data_size+i])\n",
    "    test_labels[i] = gender_list[trainig_data_size+i]\n",
    "    \n",
    "build_classification_model(train_arrays, train_labels, test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [ 0.02777437  0.02281112  0.01995092  0.01844645  0.01693605  0.01632945\n",
      "  0.01486809  0.0146083   0.01403166  0.01377665  0.01332457  0.01301072\n",
      "  0.0128515   0.01271191  0.01234352  0.01216402  0.01195215  0.01172924\n",
      "  0.01165623  0.01155279  0.01141864  0.01135101  0.01129528  0.01118586\n",
      "  0.01111427  0.01098025  0.01091225  0.01086519  0.01079161  0.01069288\n",
      "  0.01064199  0.01056684  0.01043887  0.01037184  0.01028982  0.01022637\n",
      "  0.01017484  0.01004326  0.01001328  0.00995065  0.00992581  0.00983311\n",
      "  0.00978906  0.00971328  0.00966846  0.00958847  0.00956572  0.0095356\n",
      "  0.00948062  0.00941036]\n",
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n"
     ]
    }
   ],
   "source": [
    "cluster_sample_size = 20000\n",
    "cluster_xy_vectors = twitch_commons.reduce_dim(feature_vectors[0:cluster_sample_size], 'tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = []\n",
    "for idx, g in enumerate(gender_list[0:cluster_sample_size]):\n",
    "    if g == 1:\n",
    "        colors.append((400 - rank_list[idx]))\n",
    "    else:\n",
    "        colors.append(rank_list[idx])\n",
    "        \n",
    "cm = plt.cm.get_cmap('seismic')\n",
    "plt.scatter([x[0] for x in cluster_xy_vectors],[y[1] for y in cluster_xy_vectors], c=colors, s=16, lw=0, cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
